{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FNluZesn77IT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nns\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from sklearn.model_selection import train_test_split\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, lax, value_and_grad\n",
        "import jax.random as random\n",
        "import pandas as pd\n",
        "import pylab as plt\n",
        "from scipy.stats import boxcox\n",
        "from sklearn.preprocessing import normalize\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data and Data Transformation"
      ],
      "metadata": {
        "id": "roq9eH_H2ELJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from scipy.stats import boxcox\n",
        "import numpy as np\n",
        "df = pd.read_csv('/content/drive/My Drive/tr_eikon_eod_data.csv', index_col = 0, parse_dates = True).dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD01kkLcUUzS",
        "outputId": "eb1baa59-ef38-4c3a-e888-ecb1314ec46d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aapl = pd.DataFrame(df['AAPL.O'])\n",
        "log_returns = np.log(aapl['AAPL.O'] / aapl['AAPL.O'].shift())\n",
        "log_returns = pd.DataFrame(log_returns.dropna())\n",
        "log_returns.rename(columns={\"AAPL.O\": \"log_return\"}, inplace=True)\n",
        "\n",
        "bins = [-np.inf, -0.03, -0.02, -0.015, -0.01, -0.007, -0.005, -0.003, -0.002, -0.001, -0.0005, 0,\n",
        "        0.0005, 0.001, 0.002, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, np.inf]\n",
        "\n",
        "labels = ['01Very Strong Negative', '02Strong Negative', '03Moderate Negative', '04Moderately Weak Negative',\n",
        "          '05Weak Negative', '06Slightly Weak Negative', '07Very Slightly Weak Negative', '08Extremely Weak Negative',\n",
        "          '09Super Weak Negative', '10Super Slightly Weak Negative', '11Neutral', '12Super Slightly Weak Positive',\n",
        "          '13Super Weak Positive', '14Extremely Weak Positive', '15Very Slightly Weak Positive', '16Slightly Weak Positive',\n",
        "          '17Weak Positive', '18Moderately Weak Positive', '19Moderate Positive', '20Strong Positive', '21Very Strong Positive']\n",
        "\n",
        "log_returns['category'] = pd.cut(log_returns['log_return'], bins=bins, labels=labels)\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_categories = encoder.fit_transform(log_returns['category'].values.reshape(-1, 1))\n",
        "X = []\n",
        "y = []\n",
        "window_size =20\n",
        "output_size = 1\n",
        "for i in range(len(encoded_categories) - window_size - output_size + 1):\n",
        "    X.append(encoded_categories[i:i + window_size])\n",
        "    y.append(encoded_categories[i + window_size:i + window_size + output_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1]*y_test.shape[2])\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=200, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=100, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "actual_classes = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhGAHxz-en8n",
        "outputId": "758d1257-6755-418b-9ab4-02530dfb03b9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (1693, 21)\n",
            "Shape of y_test: (424, 21)\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - 9s 99ms/step - loss: 3.0204 - accuracy: 0.0744 - val_loss: 3.0360 - val_accuracy: 0.0401\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.9743 - accuracy: 0.0762 - val_loss: 3.0316 - val_accuracy: 0.0542\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.9487 - accuracy: 0.0874 - val_loss: 3.0150 - val_accuracy: 0.0731\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9378 - accuracy: 0.0945 - val_loss: 3.0624 - val_accuracy: 0.0708\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9447 - accuracy: 0.0986 - val_loss: 3.0118 - val_accuracy: 0.0472\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9338 - accuracy: 0.0998 - val_loss: 3.0014 - val_accuracy: 0.0755\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9249 - accuracy: 0.1028 - val_loss: 3.0083 - val_accuracy: 0.0755\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9135 - accuracy: 0.1022 - val_loss: 3.0063 - val_accuracy: 0.0755\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.9138 - accuracy: 0.1034 - val_loss: 3.0081 - val_accuracy: 0.0778\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9010 - accuracy: 0.1057 - val_loss: 3.0251 - val_accuracy: 0.0778\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.9041 - accuracy: 0.1069 - val_loss: 3.0040 - val_accuracy: 0.0755\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8940 - accuracy: 0.1128 - val_loss: 2.9982 - val_accuracy: 0.0731\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8831 - accuracy: 0.1229 - val_loss: 3.0309 - val_accuracy: 0.0778\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8819 - accuracy: 0.1152 - val_loss: 3.0307 - val_accuracy: 0.0731\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8660 - accuracy: 0.1175 - val_loss: 3.0296 - val_accuracy: 0.0613\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8710 - accuracy: 0.1164 - val_loss: 3.0500 - val_accuracy: 0.0849\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8519 - accuracy: 0.1353 - val_loss: 3.0422 - val_accuracy: 0.0637\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8471 - accuracy: 0.1270 - val_loss: 3.0351 - val_accuracy: 0.0708\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.8328 - accuracy: 0.1329 - val_loss: 3.0510 - val_accuracy: 0.0849\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8268 - accuracy: 0.1323 - val_loss: 3.0653 - val_accuracy: 0.0778\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.8279 - accuracy: 0.1305 - val_loss: 3.0716 - val_accuracy: 0.0708\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8192 - accuracy: 0.1288 - val_loss: 3.0798 - val_accuracy: 0.0660\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8059 - accuracy: 0.1364 - val_loss: 3.0817 - val_accuracy: 0.0731\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7930 - accuracy: 0.1477 - val_loss: 3.0948 - val_accuracy: 0.0708\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7840 - accuracy: 0.1459 - val_loss: 3.1025 - val_accuracy: 0.0731\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7498 - accuracy: 0.1494 - val_loss: 3.1431 - val_accuracy: 0.0660\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7522 - accuracy: 0.1601 - val_loss: 3.1403 - val_accuracy: 0.0660\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7319 - accuracy: 0.1766 - val_loss: 3.1339 - val_accuracy: 0.0660\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7188 - accuracy: 0.1648 - val_loss: 3.1467 - val_accuracy: 0.0731\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.6945 - accuracy: 0.1677 - val_loss: 3.1679 - val_accuracy: 0.0660\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.6798 - accuracy: 0.1796 - val_loss: 3.1718 - val_accuracy: 0.0825\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 2.6616 - accuracy: 0.1742 - val_loss: 3.1782 - val_accuracy: 0.0708\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.6485 - accuracy: 0.1949 - val_loss: 3.1983 - val_accuracy: 0.0802\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.6406 - accuracy: 0.1890 - val_loss: 3.1932 - val_accuracy: 0.0708\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 2.6238 - accuracy: 0.1896 - val_loss: 3.1963 - val_accuracy: 0.0802\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.5956 - accuracy: 0.2120 - val_loss: 3.2078 - val_accuracy: 0.0566\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 2.5446 - accuracy: 0.2168 - val_loss: 3.2600 - val_accuracy: 0.0637\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 2.5268 - accuracy: 0.2126 - val_loss: 3.2327 - val_accuracy: 0.0896\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 2.5338 - accuracy: 0.2008 - val_loss: 3.3036 - val_accuracy: 0.0684\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.4618 - accuracy: 0.2369 - val_loss: 3.2447 - val_accuracy: 0.0873\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 2.4433 - accuracy: 0.2374 - val_loss: 3.3448 - val_accuracy: 0.0825\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.4381 - accuracy: 0.2369 - val_loss: 3.2785 - val_accuracy: 0.0896\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3969 - accuracy: 0.2510 - val_loss: 3.3601 - val_accuracy: 0.0825\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4066 - accuracy: 0.2434 - val_loss: 3.4216 - val_accuracy: 0.0849\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3765 - accuracy: 0.2558 - val_loss: 3.3915 - val_accuracy: 0.0873\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3470 - accuracy: 0.2652 - val_loss: 3.3301 - val_accuracy: 0.0967\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3068 - accuracy: 0.2865 - val_loss: 3.3655 - val_accuracy: 0.0896\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3132 - accuracy: 0.2646 - val_loss: 3.3774 - val_accuracy: 0.1038\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2591 - accuracy: 0.2877 - val_loss: 3.4125 - val_accuracy: 0.1038\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2127 - accuracy: 0.3042 - val_loss: 3.4825 - val_accuracy: 0.0802\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 3.4825 - accuracy: 0.0802\n",
            "Test Loss: 3.4825310707092285\n",
            "Test Accuracy: 0.08018867671489716\n",
            "14/14 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_first_eleven = prediction[:, :12].sum(axis=1)\n",
        "sum_last_eleven = prediction[:, 12:].sum(axis=1)\n",
        "transformed_predictions = np.column_stack((sum_first_eleven, sum_last_eleven))\n",
        "predicted_class = np.argmax(transformed_predictions, axis = 1)\n",
        "tmp = pd.DataFrame()\n",
        "tmp['direction_predicted'] = predicted_class\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 12, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "\n",
        "print(f\"Prediction Accuracy for AAPL Stock with cumulative sepreation = {accuracy * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EXs3a3WXTB2",
        "outputId": "8aa1dae9-e233-47bb-d864-61feac297d10"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Accuracy for AAPL Stock with cumulative sepreation = 52.358490566037744%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.DataFrame()\n",
        "tmp['predicted_class'] = predicted_classes\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 12, 1, 0)\n",
        "tmp['direction_predicted'] = np.where(tmp['predicted_class'] >= 12, 1, 0)\n",
        "tmp, np.sum(tmp['direction_actual']) / len(tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iapzS6kfTva",
        "outputId": "df148517-8a54-4cd3-ff4a-da5e4707fdba"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     predicted_class  actual_class  direction_actual  direction_predicted\n",
              " 0                  9            17                 1                    0\n",
              " 1                 17            16                 1                    1\n",
              " 2                 17             1                 0                    1\n",
              " 3                 17             4                 0                    1\n",
              " 4                 19             5                 0                    1\n",
              " ..               ...           ...               ...                  ...\n",
              " 419                1             3                 0                    0\n",
              " 420                1            18                 1                    0\n",
              " 421                1             8                 0                    0\n",
              " 422                1            17                 1                    0\n",
              " 423               19             7                 0                    1\n",
              " \n",
              " [424 rows x 4 columns],\n",
              " 0.49764150943396224)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For GS.N\n"
      ],
      "metadata": {
        "id": "VM5WWC-nlx0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs = pd.DataFrame(df['GS.N'])\n",
        "log_returns = np.log(gs['GS.N'] / gs['GS.N'].shift())\n",
        "log_returns = pd.DataFrame(log_returns.dropna())\n",
        "log_returns.rename(columns={\"GS.N\": \"log_return\"}, inplace=True)\n",
        "\n",
        "bins = [-np.inf, -0.01, -0.001, 0, 0.001, 0.01, np.inf]\n",
        "labels = ['1Strong Negative', '2Negative', '3Weak Negative', '4Weak Positive', '5Positive', '6Strong Positive']\n",
        "\n",
        "log_returns['category'] = pd.cut(log_returns['log_return'], bins=bins, labels=labels)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_categories = encoder.fit_transform(log_returns['category'].values.reshape(-1, 1))\n",
        "X = []\n",
        "y = []\n",
        "window_size = 5\n",
        "output_size = 1\n",
        "for i in range(len(encoded_categories) - window_size - output_size + 1):\n",
        "    X.append(encoded_categories[i:i + window_size])\n",
        "    y.append(encoded_categories[i + window_size:i + window_size + output_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1]*y_test.shape[2])\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=100))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "actual_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "tmp = pd.DataFrame()\n",
        "tmp['predicted_class'] = predicted_classes\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "tmp['direction_predicted'] = np.where(tmp['predicted_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "print(f\"Prediction Accuracy for AAPL Stock with simple sepreation = {accuracy * 100}%\")\n",
        "\n",
        "sum_first_three = prediction[:, :3].sum(axis=1)\n",
        "sum_last_three = prediction[:, 3:].sum(axis=1)\n",
        "transformed_predictions = np.column_stack((sum_first_three, sum_last_three))\n",
        "predicted_class = np.argmax(transformed_predictions, axis = 1)\n",
        "tmp = pd.DataFrame()\n",
        "tmp['direction_predicted'] = predicted_class\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "\n",
        "print(f\"Prediction Accuracy for AAPL Stock with cumulative sepreation = {accuracy * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHjLxXLll6nl",
        "outputId": "54172bdb-9574-49f2-a424-6a8a062cc31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (1705, 6)\n",
            "Shape of y_test: (427, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 5s 22ms/step - loss: 1.6195 - accuracy: 0.2475 - val_loss: 1.5647 - val_accuracy: 0.2623\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5665 - accuracy: 0.2528 - val_loss: 1.5653 - val_accuracy: 0.2693\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5612 - accuracy: 0.2639 - val_loss: 1.5571 - val_accuracy: 0.2810\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5617 - accuracy: 0.2657 - val_loss: 1.5673 - val_accuracy: 0.2600\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5567 - accuracy: 0.2680 - val_loss: 1.5719 - val_accuracy: 0.2506\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5623 - accuracy: 0.2569 - val_loss: 1.5568 - val_accuracy: 0.3091\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5563 - accuracy: 0.2762 - val_loss: 1.5576 - val_accuracy: 0.2810\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5580 - accuracy: 0.2669 - val_loss: 1.5576 - val_accuracy: 0.2763\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5538 - accuracy: 0.2716 - val_loss: 1.5623 - val_accuracy: 0.2834\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5560 - accuracy: 0.2850 - val_loss: 1.5568 - val_accuracy: 0.2482\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5516 - accuracy: 0.2827 - val_loss: 1.5722 - val_accuracy: 0.2717\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5504 - accuracy: 0.2798 - val_loss: 1.5549 - val_accuracy: 0.3162\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5483 - accuracy: 0.2856 - val_loss: 1.5681 - val_accuracy: 0.2810\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5482 - accuracy: 0.2786 - val_loss: 1.5666 - val_accuracy: 0.2482\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5500 - accuracy: 0.2704 - val_loss: 1.5566 - val_accuracy: 0.3044\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5494 - accuracy: 0.2891 - val_loss: 1.5662 - val_accuracy: 0.2763\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5444 - accuracy: 0.2804 - val_loss: 1.5619 - val_accuracy: 0.3091\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5472 - accuracy: 0.2862 - val_loss: 1.5639 - val_accuracy: 0.2810\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5419 - accuracy: 0.2909 - val_loss: 1.5759 - val_accuracy: 0.2482\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5464 - accuracy: 0.2757 - val_loss: 1.5639 - val_accuracy: 0.2482\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5398 - accuracy: 0.2938 - val_loss: 1.5671 - val_accuracy: 0.2717\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5394 - accuracy: 0.2915 - val_loss: 1.5789 - val_accuracy: 0.2717\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5370 - accuracy: 0.2897 - val_loss: 1.5708 - val_accuracy: 0.2717\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.5396 - accuracy: 0.2891 - val_loss: 1.5712 - val_accuracy: 0.2763\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5369 - accuracy: 0.2921 - val_loss: 1.5702 - val_accuracy: 0.2506\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5340 - accuracy: 0.2897 - val_loss: 1.5720 - val_accuracy: 0.2787\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5307 - accuracy: 0.2991 - val_loss: 1.5755 - val_accuracy: 0.2763\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5313 - accuracy: 0.3132 - val_loss: 1.5782 - val_accuracy: 0.2623\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5317 - accuracy: 0.2991 - val_loss: 1.5752 - val_accuracy: 0.2623\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5273 - accuracy: 0.2985 - val_loss: 1.5840 - val_accuracy: 0.2506\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5265 - accuracy: 0.3015 - val_loss: 1.5983 - val_accuracy: 0.2600\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5343 - accuracy: 0.2956 - val_loss: 1.5829 - val_accuracy: 0.2600\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5218 - accuracy: 0.3009 - val_loss: 1.5810 - val_accuracy: 0.2787\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5195 - accuracy: 0.3079 - val_loss: 1.5898 - val_accuracy: 0.2810\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5144 - accuracy: 0.3132 - val_loss: 1.5857 - val_accuracy: 0.2670\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5125 - accuracy: 0.3079 - val_loss: 1.5878 - val_accuracy: 0.2482\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5107 - accuracy: 0.3120 - val_loss: 1.5866 - val_accuracy: 0.2436\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5091 - accuracy: 0.3179 - val_loss: 1.5976 - val_accuracy: 0.2693\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5030 - accuracy: 0.3167 - val_loss: 1.6109 - val_accuracy: 0.2553\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4935 - accuracy: 0.3273 - val_loss: 1.6060 - val_accuracy: 0.2646\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5025 - accuracy: 0.3167 - val_loss: 1.6298 - val_accuracy: 0.2553\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4894 - accuracy: 0.3249 - val_loss: 1.6100 - val_accuracy: 0.2576\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4815 - accuracy: 0.3279 - val_loss: 1.6289 - val_accuracy: 0.2365\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4721 - accuracy: 0.3349 - val_loss: 1.6211 - val_accuracy: 0.2482\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4663 - accuracy: 0.3367 - val_loss: 1.6420 - val_accuracy: 0.2436\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4625 - accuracy: 0.3537 - val_loss: 1.6610 - val_accuracy: 0.2248\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4477 - accuracy: 0.3543 - val_loss: 1.6834 - val_accuracy: 0.2365\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4376 - accuracy: 0.3636 - val_loss: 1.6630 - val_accuracy: 0.2272\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4210 - accuracy: 0.3683 - val_loss: 1.6977 - val_accuracy: 0.2272\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4169 - accuracy: 0.3824 - val_loss: 1.7012 - val_accuracy: 0.2201\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.7012 - accuracy: 0.2201\n",
            "Test Loss: 1.7012344598770142\n",
            "Test Accuracy: 0.2201405167579651\n",
            "14/14 [==============================] - 1s 4ms/step\n",
            "Prediction Accuracy for AAPL Stock with simple sepreation = 46.604215456674474%\n",
            "Prediction Accuracy for AAPL Stock with cumulative sepreation = 47.07259953161593%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MSFT.O"
      ],
      "metadata": {
        "id": "AQ_g-oX6mJJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msft = pd.DataFrame(df['MSFT.O'])\n",
        "log_returns = np.log(msft['MSFT.O'] / msft['MSFT.O'].shift())\n",
        "log_returns = pd.DataFrame(log_returns.dropna())\n",
        "log_returns.rename(columns={\"MSFT.O\": \"log_return\"}, inplace=True)\n",
        "\n",
        "bins = [-np.inf, -0.01, -0.001, 0, 0.001, 0.01, np.inf]\n",
        "labels = ['1Strong Negative', '2Negative', '3Weak Negative', '4Weak Positive', '5Positive', '6Strong Positive']\n",
        "\n",
        "log_returns['category'] = pd.cut(log_returns['log_return'], bins=bins, labels=labels)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_categories = encoder.fit_transform(log_returns['category'].values.reshape(-1, 1))\n",
        "X = []\n",
        "y = []\n",
        "window_size = 5\n",
        "output_size = 1\n",
        "for i in range(len(encoded_categories) - window_size - output_size + 1):\n",
        "    X.append(encoded_categories[i:i + window_size])\n",
        "    y.append(encoded_categories[i + window_size:i + window_size + output_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1]*y_test.shape[2])\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=100))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "actual_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "tmp = pd.DataFrame()\n",
        "tmp['predicted_class'] = predicted_classes\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "tmp['direction_predicted'] = np.where(tmp['predicted_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "print(f\"Prediction Accuracy for AAPL Stock with simple sepreation = {accuracy * 100}%\")\n",
        "\n",
        "sum_first_three = prediction[:, :3].sum(axis=1)\n",
        "sum_last_three = prediction[:, 3:].sum(axis=1)\n",
        "transformed_predictions = np.column_stack((sum_first_three, sum_last_three))\n",
        "predicted_class = np.argmax(transformed_predictions, axis = 1)\n",
        "tmp = pd.DataFrame()\n",
        "tmp['direction_predicted'] = predicted_class\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "\n",
        "print(f\"Prediction Accuracy for AAPL Stock with cumulative sepreation = {accuracy * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sutgEvwPmKRG",
        "outputId": "c8af0443-154b-4fb2-9334-0944e96b7967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (1705, 6)\n",
            "Shape of y_test: (427, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 5s 21ms/step - loss: 1.6565 - accuracy: 0.2411 - val_loss: 1.6439 - val_accuracy: 0.2857\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.6025 - accuracy: 0.2669 - val_loss: 1.6250 - val_accuracy: 0.2857\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5998 - accuracy: 0.2616 - val_loss: 1.6340 - val_accuracy: 0.2998\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5984 - accuracy: 0.2534 - val_loss: 1.6471 - val_accuracy: 0.2740\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5982 - accuracy: 0.2587 - val_loss: 1.6207 - val_accuracy: 0.3021\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5942 - accuracy: 0.2499 - val_loss: 1.6336 - val_accuracy: 0.2927\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5954 - accuracy: 0.2845 - val_loss: 1.6527 - val_accuracy: 0.2857\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5952 - accuracy: 0.2592 - val_loss: 1.6392 - val_accuracy: 0.3138\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5933 - accuracy: 0.2592 - val_loss: 1.6398 - val_accuracy: 0.2881\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5932 - accuracy: 0.2610 - val_loss: 1.6209 - val_accuracy: 0.2881\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5944 - accuracy: 0.2686 - val_loss: 1.6265 - val_accuracy: 0.2904\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5909 - accuracy: 0.2434 - val_loss: 1.6255 - val_accuracy: 0.2693\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5918 - accuracy: 0.2680 - val_loss: 1.6226 - val_accuracy: 0.2740\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5882 - accuracy: 0.2774 - val_loss: 1.6302 - val_accuracy: 0.2881\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5905 - accuracy: 0.2792 - val_loss: 1.6271 - val_accuracy: 0.2881\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5917 - accuracy: 0.2616 - val_loss: 1.6215 - val_accuracy: 0.3162\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5879 - accuracy: 0.2762 - val_loss: 1.6232 - val_accuracy: 0.2998\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5853 - accuracy: 0.2909 - val_loss: 1.6180 - val_accuracy: 0.3208\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.5848 - accuracy: 0.2897 - val_loss: 1.6411 - val_accuracy: 0.3091\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 1.5845 - accuracy: 0.2804 - val_loss: 1.6375 - val_accuracy: 0.2974\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5839 - accuracy: 0.2821 - val_loss: 1.6264 - val_accuracy: 0.2998\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5830 - accuracy: 0.2827 - val_loss: 1.6519 - val_accuracy: 0.2834\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5802 - accuracy: 0.2815 - val_loss: 1.6281 - val_accuracy: 0.3021\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5809 - accuracy: 0.2933 - val_loss: 1.6311 - val_accuracy: 0.3162\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5776 - accuracy: 0.2915 - val_loss: 1.6485 - val_accuracy: 0.2881\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5772 - accuracy: 0.2874 - val_loss: 1.6523 - val_accuracy: 0.2904\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5779 - accuracy: 0.3038 - val_loss: 1.6355 - val_accuracy: 0.3021\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5724 - accuracy: 0.3026 - val_loss: 1.6616 - val_accuracy: 0.2740\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5750 - accuracy: 0.2915 - val_loss: 1.6335 - val_accuracy: 0.3138\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5736 - accuracy: 0.2833 - val_loss: 1.6573 - val_accuracy: 0.2927\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5685 - accuracy: 0.3026 - val_loss: 1.6341 - val_accuracy: 0.2998\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5681 - accuracy: 0.2974 - val_loss: 1.6434 - val_accuracy: 0.3208\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5643 - accuracy: 0.3062 - val_loss: 1.6460 - val_accuracy: 0.3044\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5586 - accuracy: 0.3062 - val_loss: 1.6617 - val_accuracy: 0.3185\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5592 - accuracy: 0.3179 - val_loss: 1.6734 - val_accuracy: 0.3162\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5529 - accuracy: 0.3050 - val_loss: 1.6552 - val_accuracy: 0.3208\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5506 - accuracy: 0.3120 - val_loss: 1.6533 - val_accuracy: 0.3115\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5454 - accuracy: 0.3097 - val_loss: 1.6603 - val_accuracy: 0.3443\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5425 - accuracy: 0.3191 - val_loss: 1.6780 - val_accuracy: 0.3068\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5413 - accuracy: 0.3308 - val_loss: 1.6802 - val_accuracy: 0.3162\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5298 - accuracy: 0.3320 - val_loss: 1.6841 - val_accuracy: 0.2974\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5279 - accuracy: 0.3466 - val_loss: 1.6843 - val_accuracy: 0.2974\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5165 - accuracy: 0.3443 - val_loss: 1.6814 - val_accuracy: 0.3208\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5098 - accuracy: 0.3443 - val_loss: 1.6928 - val_accuracy: 0.3068\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4995 - accuracy: 0.3566 - val_loss: 1.7274 - val_accuracy: 0.2787\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4871 - accuracy: 0.3560 - val_loss: 1.7359 - val_accuracy: 0.2740\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4772 - accuracy: 0.3589 - val_loss: 1.7495 - val_accuracy: 0.3021\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4650 - accuracy: 0.3783 - val_loss: 1.7680 - val_accuracy: 0.2225\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4571 - accuracy: 0.3718 - val_loss: 1.7722 - val_accuracy: 0.2763\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.4436 - accuracy: 0.3924 - val_loss: 1.7964 - val_accuracy: 0.2506\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.7964 - accuracy: 0.2506\n",
            "Test Loss: 1.7963602542877197\n",
            "Test Accuracy: 0.2505854666233063\n",
            "14/14 [==============================] - 1s 3ms/step\n",
            "Prediction Accuracy for AAPL Stock with simple sepreation = 49.88290398126464%\n",
            "Prediction Accuracy for AAPL Stock with cumulative sepreation = 50.81967213114754%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTC.O"
      ],
      "metadata": {
        "id": "pL-l0h7HnRlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intc = pd.DataFrame(df['INTC.O'])\n",
        "log_returns = np.log(intc['INTC.O'] / intc['INTC.O'].shift())\n",
        "log_returns = pd.DataFrame(log_returns.dropna())\n",
        "log_returns.rename(columns={\"INTC.O\": \"log_return\"}, inplace=True)\n",
        "\n",
        "bins = [-np.inf, -0.01, -0.001, 0, 0.001, 0.01, np.inf]\n",
        "labels = ['1Strong Negative', '2Negative', '3Weak Negative', '4Weak Positive', '5Positive', '6Strong Positive']\n",
        "\n",
        "log_returns['category'] = pd.cut(log_returns['log_return'], bins=bins, labels=labels)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_categories = encoder.fit_transform(log_returns['category'].values.reshape(-1, 1))\n",
        "X = []\n",
        "y = []\n",
        "window_size = 5\n",
        "output_size = 1\n",
        "for i in range(len(encoded_categories) - window_size - output_size + 1):\n",
        "    X.append(encoded_categories[i:i + window_size])\n",
        "    y.append(encoded_categories[i + window_size:i + window_size + output_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1]*y_test.shape[2])\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=100))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "actual_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "tmp = pd.DataFrame()\n",
        "tmp['predicted_class'] = predicted_classes\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "tmp['direction_predicted'] = np.where(tmp['predicted_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "print(f\"Prediction Accuracy for AAPL Stock with simple sepreation = {accuracy * 100}%\")\n",
        "\n",
        "sum_first_three = prediction[:, :3].sum(axis=1)\n",
        "sum_last_three = prediction[:, 3:].sum(axis=1)\n",
        "transformed_predictions = np.column_stack((sum_first_three, sum_last_three))\n",
        "predicted_class = np.argmax(transformed_predictions, axis = 1)\n",
        "tmp = pd.DataFrame()\n",
        "tmp['direction_predicted'] = predicted_class\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "\n",
        "print(f\"Prediction Accuracy for AAPL Stock with cumulative sepreation = {accuracy * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgXJEGg-mZvt",
        "outputId": "b6972a07-a7ab-48ce-e4c9-d112dc0d20fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (1705, 6)\n",
            "Shape of y_test: (427, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 4s 21ms/step - loss: 1.6603 - accuracy: 0.2387 - val_loss: 1.5931 - val_accuracy: 0.3232\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5977 - accuracy: 0.2499 - val_loss: 1.5981 - val_accuracy: 0.3279\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5952 - accuracy: 0.2633 - val_loss: 1.5919 - val_accuracy: 0.2951\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5971 - accuracy: 0.2469 - val_loss: 1.5968 - val_accuracy: 0.2904\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5898 - accuracy: 0.2504 - val_loss: 1.5782 - val_accuracy: 0.3162\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5886 - accuracy: 0.2545 - val_loss: 1.5778 - val_accuracy: 0.2904\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5887 - accuracy: 0.2475 - val_loss: 1.5788 - val_accuracy: 0.3068\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5931 - accuracy: 0.2674 - val_loss: 1.5770 - val_accuracy: 0.3255\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5822 - accuracy: 0.2733 - val_loss: 1.5871 - val_accuracy: 0.2998\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5833 - accuracy: 0.2669 - val_loss: 1.5624 - val_accuracy: 0.3232\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5812 - accuracy: 0.2674 - val_loss: 1.5894 - val_accuracy: 0.2834\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5815 - accuracy: 0.2680 - val_loss: 1.5777 - val_accuracy: 0.3115\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5813 - accuracy: 0.2821 - val_loss: 1.5802 - val_accuracy: 0.2927\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5777 - accuracy: 0.2862 - val_loss: 1.5923 - val_accuracy: 0.2717\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5746 - accuracy: 0.2891 - val_loss: 1.5836 - val_accuracy: 0.3138\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.5733 - accuracy: 0.2786 - val_loss: 1.5862 - val_accuracy: 0.2927\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5735 - accuracy: 0.2757 - val_loss: 1.5967 - val_accuracy: 0.2600\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5677 - accuracy: 0.2886 - val_loss: 1.6135 - val_accuracy: 0.2553\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5679 - accuracy: 0.2891 - val_loss: 1.5871 - val_accuracy: 0.2857\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5664 - accuracy: 0.2827 - val_loss: 1.6112 - val_accuracy: 0.2670\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 1.5637 - accuracy: 0.2862 - val_loss: 1.5942 - val_accuracy: 0.2998\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5584 - accuracy: 0.2968 - val_loss: 1.5992 - val_accuracy: 0.3068\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5572 - accuracy: 0.3009 - val_loss: 1.6037 - val_accuracy: 0.2670\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5536 - accuracy: 0.2997 - val_loss: 1.6125 - val_accuracy: 0.2951\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5506 - accuracy: 0.3050 - val_loss: 1.6159 - val_accuracy: 0.2670\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5514 - accuracy: 0.2950 - val_loss: 1.6061 - val_accuracy: 0.2951\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5458 - accuracy: 0.3067 - val_loss: 1.6150 - val_accuracy: 0.2951\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5394 - accuracy: 0.3179 - val_loss: 1.5967 - val_accuracy: 0.3068\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.5372 - accuracy: 0.3138 - val_loss: 1.6075 - val_accuracy: 0.2857\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5312 - accuracy: 0.3032 - val_loss: 1.6155 - val_accuracy: 0.2810\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5273 - accuracy: 0.3214 - val_loss: 1.6395 - val_accuracy: 0.2927\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5203 - accuracy: 0.3290 - val_loss: 1.6778 - val_accuracy: 0.2857\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5080 - accuracy: 0.3320 - val_loss: 1.7178 - val_accuracy: 0.2553\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5172 - accuracy: 0.3255 - val_loss: 1.6948 - val_accuracy: 0.2529\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5044 - accuracy: 0.3296 - val_loss: 1.6521 - val_accuracy: 0.2810\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4833 - accuracy: 0.3543 - val_loss: 1.6916 - val_accuracy: 0.2787\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4789 - accuracy: 0.3531 - val_loss: 1.7222 - val_accuracy: 0.2717\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4710 - accuracy: 0.3619 - val_loss: 1.7184 - val_accuracy: 0.2740\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4549 - accuracy: 0.3695 - val_loss: 1.7448 - val_accuracy: 0.2670\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4479 - accuracy: 0.3666 - val_loss: 1.7523 - val_accuracy: 0.2553\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4417 - accuracy: 0.3742 - val_loss: 1.7632 - val_accuracy: 0.2553\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4188 - accuracy: 0.3889 - val_loss: 1.7768 - val_accuracy: 0.2670\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4023 - accuracy: 0.3912 - val_loss: 1.8032 - val_accuracy: 0.2763\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.3804 - accuracy: 0.3965 - val_loss: 1.8096 - val_accuracy: 0.2810\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.3696 - accuracy: 0.4152 - val_loss: 1.8782 - val_accuracy: 0.2600\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.3493 - accuracy: 0.4199 - val_loss: 1.8824 - val_accuracy: 0.2412\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.3275 - accuracy: 0.4235 - val_loss: 1.9129 - val_accuracy: 0.2529\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 1.2986 - accuracy: 0.4469 - val_loss: 1.9612 - val_accuracy: 0.2693\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.2818 - accuracy: 0.4545 - val_loss: 2.0013 - val_accuracy: 0.2553\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.2573 - accuracy: 0.4692 - val_loss: 2.0103 - val_accuracy: 0.2787\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.0103 - accuracy: 0.2787\n",
            "Test Loss: 2.0103325843811035\n",
            "Test Accuracy: 0.2786885201931\n",
            "14/14 [==============================] - 1s 3ms/step\n",
            "Prediction Accuracy for AAPL Stock with simple sepreation = 52.69320843091335%\n",
            "Prediction Accuracy for AAPL Stock with cumulative sepreation = 48.711943793911004%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMZN.O"
      ],
      "metadata": {
        "id": "WPv_NSXMnUHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amzn = pd.DataFrame(df['AMZN.O'])\n",
        "log_returns = np.log(amzn['AMZN.O'] / amzn['AMZN.O'].shift())\n",
        "log_returns = pd.DataFrame(log_returns.dropna())\n",
        "log_returns.rename(columns={\"AMZN.O\": \"log_return\"}, inplace=True)\n",
        "\n",
        "bins = [-np.inf, -0.01, -0.001, 0, 0.001, 0.01, np.inf]\n",
        "labels = ['1Strong Negative', '2Negative', '3Weak Negative', '4Weak Positive', '5Positive', '6Strong Positive']\n",
        "\n",
        "log_returns['category'] = pd.cut(log_returns['log_return'], bins=bins, labels=labels)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_categories = encoder.fit_transform(log_returns['category'].values.reshape(-1, 1))\n",
        "X = []\n",
        "y = []\n",
        "window_size = 5\n",
        "output_size = 1\n",
        "for i in range(len(encoded_categories) - window_size - output_size + 1):\n",
        "    X.append(encoded_categories[i:i + window_size])\n",
        "    y.append(encoded_categories[i + window_size:i + window_size + output_size])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1]*y_train.shape[2])\n",
        "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1]*y_test.shape[2])\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=100))\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "predicted_classes = np.argmax(prediction, axis=1)\n",
        "actual_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "tmp = pd.DataFrame()\n",
        "tmp['predicted_class'] = predicted_classes\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "tmp['direction_predicted'] = np.where(tmp['predicted_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "print(f\"Prediction Accuracy for AAPL Stock with simple sepreation = {accuracy * 100}%\")\n",
        "\n",
        "sum_first_three = prediction[:, :3].sum(axis=1)\n",
        "sum_last_three = prediction[:, 3:].sum(axis=1)\n",
        "transformed_predictions = np.column_stack((sum_first_three, sum_last_three))\n",
        "predicted_class = np.argmax(transformed_predictions, axis = 1)\n",
        "tmp = pd.DataFrame()\n",
        "tmp['direction_predicted'] = predicted_class\n",
        "tmp['actual_class'] = actual_classes\n",
        "tmp['direction_actual'] = np.where(tmp['actual_class'] >= 3, 1, 0)\n",
        "accuracy = np.sum(tmp['direction_predicted'] == tmp['direction_actual']) / len(tmp)\n",
        "\n",
        "print(f\"Prediction Accuracy for AAPL Stock with cumulative sepreation = {accuracy * 100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ox5LTJynVW-",
        "outputId": "cebe17cc-14c6-489f-9e37-dffa8cdef27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (1705, 6)\n",
            "Shape of y_test: (427, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 6s 22ms/step - loss: 1.6365 - accuracy: 0.2751 - val_loss: 1.6001 - val_accuracy: 0.2365\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5569 - accuracy: 0.2886 - val_loss: 1.6068 - val_accuracy: 0.2459\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5462 - accuracy: 0.2944 - val_loss: 1.5905 - val_accuracy: 0.2904\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5510 - accuracy: 0.2856 - val_loss: 1.6022 - val_accuracy: 0.2553\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5504 - accuracy: 0.2903 - val_loss: 1.6219 - val_accuracy: 0.2389\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5473 - accuracy: 0.2897 - val_loss: 1.6020 - val_accuracy: 0.2553\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5462 - accuracy: 0.2850 - val_loss: 1.6158 - val_accuracy: 0.2365\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5501 - accuracy: 0.2891 - val_loss: 1.5939 - val_accuracy: 0.2717\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5445 - accuracy: 0.2856 - val_loss: 1.6038 - val_accuracy: 0.2693\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5457 - accuracy: 0.2921 - val_loss: 1.6068 - val_accuracy: 0.2576\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5430 - accuracy: 0.2968 - val_loss: 1.5914 - val_accuracy: 0.3021\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5410 - accuracy: 0.2856 - val_loss: 1.6336 - val_accuracy: 0.2529\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.5422 - accuracy: 0.2903 - val_loss: 1.6025 - val_accuracy: 0.2646\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.5406 - accuracy: 0.2962 - val_loss: 1.6043 - val_accuracy: 0.2553\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.5354 - accuracy: 0.2962 - val_loss: 1.6126 - val_accuracy: 0.2600\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5364 - accuracy: 0.3003 - val_loss: 1.6084 - val_accuracy: 0.2319\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5358 - accuracy: 0.3114 - val_loss: 1.5919 - val_accuracy: 0.2834\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5382 - accuracy: 0.3132 - val_loss: 1.6115 - val_accuracy: 0.2670\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5320 - accuracy: 0.3126 - val_loss: 1.6167 - val_accuracy: 0.2482\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5315 - accuracy: 0.3091 - val_loss: 1.6387 - val_accuracy: 0.2201\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5296 - accuracy: 0.3056 - val_loss: 1.6063 - val_accuracy: 0.2576\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5260 - accuracy: 0.3161 - val_loss: 1.6101 - val_accuracy: 0.2506\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5260 - accuracy: 0.3003 - val_loss: 1.6175 - val_accuracy: 0.2576\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5211 - accuracy: 0.3144 - val_loss: 1.6197 - val_accuracy: 0.2412\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5225 - accuracy: 0.3085 - val_loss: 1.6122 - val_accuracy: 0.2646\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5160 - accuracy: 0.3220 - val_loss: 1.6041 - val_accuracy: 0.2553\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5162 - accuracy: 0.3167 - val_loss: 1.6221 - val_accuracy: 0.2482\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5130 - accuracy: 0.3232 - val_loss: 1.6108 - val_accuracy: 0.2412\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5109 - accuracy: 0.3144 - val_loss: 1.6267 - val_accuracy: 0.2600\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5048 - accuracy: 0.3132 - val_loss: 1.6325 - val_accuracy: 0.2389\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.5030 - accuracy: 0.3173 - val_loss: 1.6475 - val_accuracy: 0.2319\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4996 - accuracy: 0.3302 - val_loss: 1.6389 - val_accuracy: 0.2529\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4936 - accuracy: 0.3273 - val_loss: 1.6421 - val_accuracy: 0.2436\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4972 - accuracy: 0.3243 - val_loss: 1.6299 - val_accuracy: 0.2529\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4912 - accuracy: 0.3337 - val_loss: 1.6289 - val_accuracy: 0.2693\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4868 - accuracy: 0.3390 - val_loss: 1.6285 - val_accuracy: 0.2693\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4876 - accuracy: 0.3279 - val_loss: 1.6704 - val_accuracy: 0.2342\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4764 - accuracy: 0.3279 - val_loss: 1.6546 - val_accuracy: 0.2646\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4723 - accuracy: 0.3361 - val_loss: 1.6881 - val_accuracy: 0.2600\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4654 - accuracy: 0.3501 - val_loss: 1.6640 - val_accuracy: 0.2646\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.4595 - accuracy: 0.3543 - val_loss: 1.6885 - val_accuracy: 0.2576\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 1.4594 - accuracy: 0.3390 - val_loss: 1.6999 - val_accuracy: 0.2623\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.4469 - accuracy: 0.3496 - val_loss: 1.7215 - val_accuracy: 0.2482\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 1.4432 - accuracy: 0.3584 - val_loss: 1.7010 - val_accuracy: 0.2529\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 1.4412 - accuracy: 0.3648 - val_loss: 1.6920 - val_accuracy: 0.2600\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4387 - accuracy: 0.3607 - val_loss: 1.7178 - val_accuracy: 0.2412\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4250 - accuracy: 0.3754 - val_loss: 1.7447 - val_accuracy: 0.2529\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.4098 - accuracy: 0.3701 - val_loss: 1.7552 - val_accuracy: 0.2342\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 1.4110 - accuracy: 0.3683 - val_loss: 1.7501 - val_accuracy: 0.2342\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 1.3971 - accuracy: 0.3959 - val_loss: 1.8082 - val_accuracy: 0.2506\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8082 - accuracy: 0.2506\n",
            "Test Loss: 1.8082423210144043\n",
            "Test Accuracy: 0.2505854666233063\n",
            "14/14 [==============================] - 1s 3ms/step\n",
            "Prediction Accuracy for AAPL Stock with simple sepreation = 53.86416861826698%\n",
            "Prediction Accuracy for AAPL Stock with cumulative sepreation = 52.92740046838408%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aapl = pd.DataFrame(df['AAPL.O'])"
      ],
      "metadata": {
        "id": "yX_OETIusyEU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten, Reshape\n",
        "\n",
        "# Assuming you have loaded your data into a DataFrame named 'aapl'\n",
        "time_series_data = aapl['AAPL.O'].values\n",
        "\n",
        "def create_dataset(time_series_data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(time_series_data) - n_steps):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix + 10 < len(time_series_data):\n",
        "            X.append(time_series_data[i:end_ix])\n",
        "            y.append(1 if time_series_data[end_ix + 1] > time_series_data[end_ix] else 0)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 40\n",
        "\n",
        "X, y = create_dataset(time_series_data, n_steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)\n",
        "\n",
        "# Normalize the input features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape input features for CNN input\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "9_T9KzrYL1IN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=26, activation='relu', input_shape=(40, 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Reshape output of CNN to match LSTM input shape\n",
        "cnn_model.add(Reshape((-1, cnn_model.output_shape[1])))\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(1, cnn_model.output_shape[2])))  # Input shape: (batch_size, timesteps, features)\n",
        "\n",
        "# Combine the models\n",
        "combined_model = Sequential()\n",
        "combined_model.add(cnn_model)\n",
        "combined_model.add(lstm_model)\n",
        "combined_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the combined model\n",
        "combined_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9pi2LipNS4i",
        "outputId": "da778c47-e09c-4828-d7ca-7409cf5fa43f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "42/42 [==============================] - 3s 17ms/step - loss: 0.6937 - accuracy: 0.5269 - val_loss: 0.6931 - val_accuracy: 0.4970\n",
            "Epoch 2/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5150 - val_loss: 0.7037 - val_accuracy: 0.4970\n",
            "Epoch 3/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5292 - val_loss: 0.6930 - val_accuracy: 0.4970\n",
            "Epoch 4/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.5269 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
            "Epoch 5/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5217 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 6/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5142 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 7/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.5269 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 8/10\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.5269 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
            "Epoch 9/10\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.5269 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 10/10\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.5269 - val_loss: 0.6939 - val_accuracy: 0.4970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a077c5b2c80>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VspqMmD0WYPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}